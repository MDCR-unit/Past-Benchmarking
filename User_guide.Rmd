---
title: "Automatic Updating for the Benchmarking Database"
author: "A user's guide to accessing APIs and remote downloading in R for the benchmarking module"
date: "17-November-2020"
output:
  html_document: 
    highlight: tango
---

There are several sources that are used in Benchmarking Database each with their own unique methods for searching, downloading and cleaning the datasets. This guide details these methods for the following sources:

* FAOSTAT
* UIS (UNESCO)
* ILO
* WHO
* OECD

Two other databases are accessed with Stata where they are joined with this one and cleaned for executing found under the file name **Benchmark Database.do**. Different methods of integration may be attempted later to move the Benchmarking Database onto a single software. 

Note: this R script has been cleaned and prepared to match the data in Stata - if data cleaning methods are adjusted on Stata file then they should also be adjusted here. 

---

### Installing libraries

To start, install/update the packages that will be used. The libraries should be loaded in stages rather than all at the start because there may be commands that are masked by other libraries. 

```{r ,  eval=FALSE} 
rm(list = ls())

install.packages(c("imfr","rgho","MazamaSpatialUtils","Rilostat","countrycode",
                    "OECD","BIS","lubridate","dplyr","devtools","FAOSTAT"))
```
---

### FAOSTAT Dataset

The FAOSTAT database can be found at this [link](http://www.fao.org/faostat/en/#home). Under **Database description** you can select the XML option - also found [here](http://fenixservices.fao.org/faostat/static/bulkdownloads/datasets_E.xml). The required datasets can be located within this link by searching keywords using CTRL+F, finding the dataset you are looking for and copying the zip file link. 

For example search "land use", read the dataset description to ensure it is the one you want and copy the corresponding zip url - which is found between the "<file location>" brackets. This method avoids downloading the entire database which would be much slower.

The indicators we are searching for come from the **Agri-Environmental Indicators: Land use indicators** dataset, libraries countrycode (to change country names to iso3) and dplyr (a data manipulation library) are employed. The zip file url is designated as url.land and unzipped using a temporary file. 

```{r ,  eval=FALSE} 
library(countrycode)
library(dplyr)

# Land use data
url.land<-"http://fenixservices.fao.org/faostat/static/bulkdownloads/Environment_LandUse_E_All_Data_(Normalized).zip"

temp <- tempfile()
download.file(url.land, temp)
unzip(temp, "Environment_LandUse_E_All_Data_(Normalized).csv")
landuse <- read.csv("Environment_LandUse_E_All_Data_(Normalized).csv")
unlink(temp)

View(landuse)
```

The next step is to view the dataset and find the desired indicators. For land use we are looking for:  <p>
* Agricultural land (% of land area) 
* Arable land (% of land area)
* Forest area (% of land area)

We see these are separated by country under the column name **Item** when using the ```View``` command to look at the dataset. Using dplyr the different variables are subsetted, cleaned, assigned indicator names/codes then rejoined. 

There should be 5 variables total and the column headers should all match. The names should be:  <p>
* "iso3c"  
* "year" 
* "VALUE" 
* "indicatorcode"
* "source"

Iso3c is the code for each country which should be checked to be in proper denotation (done at the end). Cat and subcat are the categories, where 3 organizes the indicators by the 3 P's and subcat divides them further into more specific groups. Denotations are found on the *Benchmarking List of Indicators* excel sheet. Finally, please note that R commands are case sensitive so ensure that the column names match above. 

```{r,  eval=FALSE} 
# % Agricultural
agriland <- landuse[landuse$Item %in% "Agricultural land",]
agriland<-agriland[,-c(1,3:6,8:9,11)]
names(agriland)[1:3] <-c("iso3c","year","VALUE")
agriland$indicatorname <- "Agricultural land (% of land area)"
agriland$indicatorcode <- "FAO.AGRI"

# % Arable
arabland<-landuse[landuse$Item %in% "Arable land",]
arabland<-arabland[,-c(1,3:6,8:9,11)]
names(arabland)[1:3]<-c("iso3c","year","VALUE")
arabland$indicatorname<-"Arable land (% of land area)"
arabland$indicatorcode<-"FAO.ARABLE"

# % Forest
forestland<-landuse[landuse$Item %in% "Forest land",]
forestland<-forestland[,-c(1,3:6,8:9,11)]
names(forestland)[1:3]<-c("iso3c","year","VALUE")
forestland$indicatorname<-"Forest area (% of land area)"
forestland$indicatorcode<-"FAO.FOREST"

fao <- rbind(agriland,arabland,forestland)
```

**Note:** This dataset is very easy to clean because the same cleaning code can be used for each indicator, but this is not always the case. Always make sure to edit the code to match the data. 

Further cleaning for these indicators include removing region designations, outdated country names and broken values using dplyr. A list of countries to be removed  The remaining country names are reassigned to ISO3 codes. Finally the source is assigned. 

```{r,  eval=FALSE} 
Country<-c("Africa", "Americas", "Asia", "Australia and New Zealand", "Belgium-Luxembourg", 
          "Caribbean", "Central America","Central Asia", "Channel Islands", "Czechoslovakia", 
          "Eastern Africa", "Eastern Asia", "Eastern Europe", "Europe", "European Union (27)", 
          "European Union (28)", "Land Locked Developing Countries", "Least Developed Countries", 
          "Low Income Food Deficit Countries", "Melanesia", "Micronesia", "Middle Africa", 
          "Net Food Importing Developing Countries", "Netherlands Antilles (former)", 
          "Northern Africa", "Northern America","Northern Europe", "Oceania", "OECD", 
          "Pacific Islands Trust Territory", "Polynesia", "R<e9>union", 
          "Serbia and Montenegro","Small Island Developing States", "South America", 
          "South-eastern Asia", "Southern Africa", "Southern Asia", "Southern Europe", 
          "Western Africa", "Western Asia", "Western Europe", "World","Yugoslav SFR")

fao <- filter(fao, !(iso3c %in% Country))

fao1<-countrycode(fao$iso3c, origin = 'country.name', destination = 'iso3c')
fao<-data.frame(fao,fao1)

fao<-fao[,-1]
names(fao)[5] <-"iso3c"

fao$cat <- "0. Structural" 
fao$subcat <- "0.1 Natural endowments"
fao$source <- "FAO"
```

This completes the FAOSTAT database.

-----

### UIS Dataset

The UIS UNESCO database is moving towards a subscription based SDMX API - which poses challenges - but also provides bulk data downloading which is similar to what we did before with FAOSTAT.

The main difference is finding the dataset you want to use, which is done online at this [link](https://apiportal.uis.unesco.org/bdds). Once on the website you can toggle between **Education, Science, Culture, etc.** to find the relevant dataset. Next hover over the **Download the data** button for the chosen dataset, right click and select **Copy Link Address**. This is a link to the dataset's zip file which will be used to remote download. 

For UIS, the indicators used in the Benchmarking Database are focused on education. So we use both available datasets under the education option; **National Monitoring** and **SDG Global and Thematic Indicators**. We name the zip url link and upload it onto the environment using a temporary file like we did with FAOSTAT but also capture the labels so we know what we are looking at. We can then find the indicators we want using either using the ```View``` command for the label dataset and then CTRL+F, finding code. Once found, the dataset is parsed out using the code id and dplyr then cleaned to 7 variables, as before. Finally it is combined with FAOSTAT using ```rbind```. 

#### UIS National Monitoring Indicators 

For this dataset we are looking for:  <p>
- Government expenditure on education, total (% of GDP)
- School enrollment, primary (% net)
- School enrollment, secondary (% gross)
- School enrollment, primary and secondary (gross), gender parity index (GPI)
- Mean years of schooling (ISCED 1 or higher), population 25+ years, both sexes

```{r,  eval=FALSE} 
# ******** UIS Education indicators ********
urluis<-"ftp://ftp.uis.unesco.org/BDDS/NATMON.zip"

temp <- tempfile()
download.file(urluis, temp)
unzip(temp, "NATMON_DATA_NATIONAL.csv")
uis <- read.csv("NATMON_DATA_NATIONAL.csv")
unlink(temp)

# Govt exp on educ
educexp <- uis[uis$INDICATOR_ID %in% "XGDP.FSgov" ,]
educexp<-educexp[,-c(1,5,6)]
names(educexp)[1:3] <-c("iso3c","year","VALUE")
educexp$indicatorname <- "Government expenditure on education, total (% of GDP)"
educexp$indicatorcode <- "uis.XPD.TOTL.GD.ZS"

# Primary enroll (net)
netprim <- uis[uis$INDICATOR_ID %in% "NERT.1.cp" ,]
netprim<-netprim[,-c(1,5,6)]
names(netprim)[1:3] <-c("iso3c","year","VALUE")
netprim$indicatorname <- "School enrollment, primary (% net)"
netprim$indicatorcode <- "uis.PRM.NENR"

# Secondary enroll (gross)
grosecond <- uis[uis$INDICATOR_ID %in% "GER.2t3" ,]
grosecond<-grosecond[,-c(1,5,6)]
names(grosecond)[1:3] <-c("iso3c","year","VALUE")
grosecond$indicatorname <- "School enrollment, secondary (% net)"
grosecond$indicatorcode <- "uis.SEC.NENR"

# Enrollment ratio (GPI)
enrolld <- uis[uis$INDICATOR_ID %in% "GER.1t3.GPI" ,]
enrolld<-enrolld[,-c(1,5,6)]
names(enrolld)[1:3] <-c("iso3c","year","VALUE")
enrolld$indicatorname <- "School enrollment, primary and secondary (gross), gender parity index (GPI)"
enrolld$indicatorcode <- "UIS.ENR.PRSC.FM.ZS"
enrolld$subcat <- "1.8 Gender equality"

# Mean schooling
avgschool <- uis[uis$INDICATOR_ID %in% "MYS.1t8.Ag25t99" ,]
avgschool<-avgschool[,-c(1,5,6)]
names(avgschool)[1:3] <-c("iso3c","year","VALUE")
avgschool$indicatorname <- "Mean years of schooling (ISCED 1 or higher), population 25+ years, both sexes"
avgschool$indicatorcode <- "uis.SCHOOLING"

uis1 <-rbind(educexp,netprim,grosecond,avgschool)
uis1$subcat <-"1.6 Education"

uisdf <- rbind(uis1, enrolld)
```

#### UIS SDG Global and Thematic Indicators

We now move on to the SDG Global dataset using the new zip link and follow the same methods for the following indicators: <p>
- School enrollment, preprimary (% gross) 
- Primary completion rate, total (% of relevant age group) 
- Pupil-(qualified) teacher ratio, primary
- Proportion of students at the end of primary education achieving at least a minimum proficiency level in mathematics, both sexes (%)
- Proportion of students at the end of primary education achieving at least a minimum proficiency level in reading, both sexes (%)
- Literacy rate, adult total (% of people ages 15 and above)

```{r,  eval=FALSE} 
# ******** UIS SDG education indicators ********
urlsdg <-"ftp://ftp.uis.unesco.org/BDDS/SDG.zip"

temp <- tempfile()
download.file(urlsdg, temp)
unzip(temp, "SDG_DATA_NATIONAL.csv")
sdg <- read.csv("SDG_DATA_NATIONAL.csv")
unlink(temp)

# Pre primary enrollment
preprim <- sdg[sdg$INDICATOR_ID %in% "GER.02" ,]
preprim<-preprim[,-c(1,5,6)]
names(preprim)[1:3] <-c("iso3c","year","VALUE")
preprim$indicatorname <- "School enrollment, preprimary (% gross)"
preprim$indicatorcode <- "uis.PRE.ENRR"

# Primary completion
complet <- sdg[sdg$INDICATOR_ID %in% "CR.1" ,]
complet<-complet[,-c(1,5,6)]
names(complet)[1:3] <-c("iso3c","year","VALUE")
complet$indicatorname <- "Primary completion rate, total (% of relevant age group)"
complet$indicatorcode <- "uis.COMPLRATE.PRIMARY"

# Pupil (qualified) teacher ratio
tratio <- sdg[sdg$INDICATOR_ID %in% "PTRHC.1.qualified" ,]
tratio<-tratio[,-c(1,5,6)]
names(tratio)[1:3] <-c("iso3c","year","VALUE")
tratio$indicatorname <- "Pupil-teacher ratio, primary"
tratio$indicatorcode <- "uis.PRM.ENRL.TC.ZS"

# Math proficiency 
math <- sdg[sdg$INDICATOR_ID %in% "Math.Primary" ,]
math<-math[,-c(1,5,6)]
names(math)[1:3] <-c("iso3c","year","VALUE")
math$indicatorname <-"Proportion of students at the end of primary education achieving at least a minimum proficiency level in mathematics, both sexes (%)"
math$indicatorcode <- "uis_math"

# Reading proficiency 
read <- sdg[sdg$INDICATOR_ID %in% "Read.Primary" ,]
read<-read[,-c(1,5,6)]
names(read)[1:3] <-c("iso3c","year","VALUE")
read$indicatorname <-"Proportion of students at the end of primary education achieving at least a minimum proficiency level in reading, both sexes (%)"
read$indicatorcode <- "uis_reading"

# Literacy rate
lit <- sdg[sdg$INDICATOR_ID %in% "LR.Ag15t99" ,]
lit<-lit[,-c(1,5,6)]
names(lit)[1:3] <-c("iso3c","year","VALUE")
lit$indicatorname <-"Literacy rate, adult total (% of people ages 15 and above)"
lit$indicatorcode <- "uis.ADT.LITR.ZS"

sdg <- rbind(math,read,lit,tratio,complet,preprim)
sdg$subcat <- "1.6 Education"
```

Once that is finished the data is binded and the source is assigned. Now the full benchmark dataframe will start to be established by combining the FAO and UIS dataframes. 

```{r,  eval=FALSE} 
unesco<-rbind(uisdf,sdg)
unesco$source <- "UIS"
unesco$cat <- "1. People"

benchmark <- rbind(fao,unesco)
```
---

### ILOSTAT dataset

We now move onto the ILO database. This data is sourced using a pre-built library that accesses the API, parses the HTML and provides a clean data format for its users. Since the package is updated and maintained by ILO we can be sure of its quality. The link for the CRAN library and commands can be found [here](https://cran.r-project.org/web/packages/Rilostat/Rilostat.pdf) and a user-guide [here](https://cran.r-project.org/web/packages/Rilostat/vignettes/Rilostat.html). 

This dataset is not as straightforward as before. This is because, rather than parsing from one global dataset, one must first search the ILO database for the corresponding dataset using the ```get_ilostat_toc``` command, find here the correct dataset, input the corresponding **id** code into the ```get_ilostat``` command to call the dataset and then parse the indicators from there.

```{r,  eval=FALSE} 
library(Rilostat)

# Search database for indicators
toc <- get_ilostat_toc()
```

In ILO we are looking for the following indicators:  <p>
- Unemployment, total (% of total labor force) (modeled ILO estimate)
- Labor force participation rate, total (% of total population ages 15+) (modeled ILO estimate)
- Labor force participation rate, female (% of female population ages 15+) (modeled ILO estimate)
- Unemployment, youth total (% of total labor force ages 15-24) (modeled ILO estimate)
- Employment in agriculture (% of total employment) (modeled ILO estimate)
- Employment in industry (% of total employment) (modeled ILO estimate)
- Employment in services (% of total employment) (modeled ILO estimate)
- Share of labour force with basic education (25+ yo)
- Share of labour force with intermediate education (25+ yo)
- Share of labour force with advanced education (25+ yo)

It is possible to filter the data with the ```get_ilostat``` command to improve downloading speeds, but usually the full dataset will have to be downloaded first. This is so you can understand what needs to be filtered in order to find the correct indicator among available data. The code included here is already filtered to improve download times, but this should be kept in mind in case the Benchmark indicators are changed.

The first example is for total unemployment. We use ```get_ilostat``` with the id code found through the search function, which is **SDG_0852_SEX_AGE_RT_A**, segment set to indicator (rather than ref area which will give you country/regional data) as well as the appropriate filters for this dataset using column names and specifying which values you want. Here we have specified **sex=T** for both sexes (a common one for ILO data) and the age group desired under the classif1 column. Excess columns are then dropped, columns renamed and indicator code/names, cat/subcat are assigned.

```{r,  eval=FALSE} 
# Total unemployment % labor force (15-64) 
unemp <- get_ilostat(id = "SDG_0852_SEX_AGE_RT_A", segment = 'indicator', filters=list(sex="T",classif1="AGE_YTHADULT_Y15-64"))
unemp<-unemp[,-c(2:5,8:11)]

names(unemp)[c(1:3)] <-c("iso3c","year","VALUE")
unemp$indicatorname <- "Unemployment, total (% of total labor force) (modeled ILO estimate)"
unemp$indicatorcode <- "ILO.UNEMP.15"
unemp$subcat <- "2.2 Labour market"
```

The rest of the dataset is similar. More often than not more than one indicator is found in a dataset and they are subsetted using dplyr's %in% command. Filtering is done as necessary. 

```{r,  eval=FALSE} 
# Youth employment
youth <- get_ilostat(id = "UNE_2UNE_SEX_AGE_NB_A", segment = 'indicator',filters = list(sex="T",classif1="AGE_YTHADULT_Y15-24")) 
youth<-youth[,-c(2:5,8)]
names(youth)[c(1:3)] <-c("iso3c","year","VALUE")
youth$indicatorname <- "Unemployment, youth total (% of total labor force ages 15-24) (modeled ILO estimate)"
youth$indicatorcode <- "ILO.UNEMP.1524"
youth$subcat <- "2.2 Labour market"

# --- Labor force participation ---
lpartic <- get_ilostat(id = "EAP_2WAP_SEX_AGE_RT_A", filters = list(classif1 = 'AGE_AGGREGATE_TOTAL'),segment = 'indicator') 

# Total labor force participation 
partic <- lpartic[lpartic$sex %in% "SEX_T",]
partic<-partic[,-c(2:5,8)]
names(partic)[c(1:3)] <-c("iso3c","year","VALUE")
partic$indicatorname <- "Labor force participation rate, total (% of total population ages 15+) (modeled ILO estimate)"
partic$indicatorcode <- "ILO.LF"
partic$subcat <- "2.2 Labour market"

# Female labor force participation 
female <- lpartic[lpartic$sex %in% "SEX_F",]
female<-female[,-c(2:5,8)]
names(female)[c(1:3)] <-c("iso3c","year","VALUE")
female$indicatorname <- "Labor force participation rate, female (% of female population ages 15+) (modeled ILO estimate)"
female$indicatorcode <- "UIS.TLF.CACT.FE.ZS"
female$cat <- "1. People"
female$subcat <- "1.8 Gender equality"

# --- Employment by economic activity ---
econact <- get_ilostat(id = "EMP_TEMP_SEX_ECO_DT_A", segment = 'indicator', filters = list(sex = 'T',classif1=c("ECO_SECTOR_IND","ECO_SECTOR_AGR","ECO_SECTOR_SER"))) 

# Agriculture employment
agri <- econact[econact$classif1 %in% "ECO_SECTOR_AGR",]
agri<-agri[,-c(2:5,8:11)]
names(agri)[c(1:3)] <-c("iso3c","year","VALUE")
agri$indicatorname <- "Employment in agriculture (% of total employment) (modeled ILO estimate)"
agri$indicatorcode <- "ILO.EMPL.AGRI"
agri$subcat <- "2.2 Labour market"

# Industrial employment
indus <- econact[econact$classif1 %in% "ECO_SECTOR_IND",]
indus<-indus[,-c(2:5,8:11)]
names(indus)[c(1:3)] <-c("iso3c","year","VALUE")
indus$indicatorname <- "Employment in industry (% of total employment) (modeled ILO estimate)"
indus$indicatorcode <- "ILO.EMPL.INDUSTRY"
indus$subcat <- "2.2 Labour market"

# Service employment 
serv <- econact[econact$classif1 %in% "ECO_SECTOR_SER",]
serv<-serv[,-c(2:5,8:11)]
names(serv)[c(1:3)] <-c("iso3c","year","VALUE")
serv$indicatorname <- "Employment in services (% of total employment) (modeled ILO estimate)"
serv$indicatorcode <- "ILO.EMPL.SERVICES"
serv$subcat <- "2.2 Labour market"

# --- Labor force by education level ---
educ <- get_ilostat(id = "EAP_TEAP_SEX_AGE_EDU_DT_A", segment = 'indicator',filters = list(sex = 'T',classif1="AGE_AGGREGATE_TOTAL")) 

# % with basic education
bas<-educ[educ$classif2 %in% "EDU_AGGREGATE_BAS",]
bas<-bas[,-c(2:6,9:12)]
names(bas)[c(1:3)] <-c("iso3c","year","VALUE")
bas$indicatorname <- "Share of labour force with basic education (25+ yo)"
bas$indicatorcode <- "ILO.EMPL.EDUBASIC"
bas$subcat <- "2.3 Productive capabilities"

# % with intermediate education
int<-educ[educ$classif2 %in% "EDU_AGGREGATE_INT",]
int<-int[,-c(2:6,9:12)]
names(int)[c(1:3)] <-c("iso3c","year","VALUE")
int$indicatorname <- "Share of labour force with intermediate education (25+ yo)"
int$indicatorcode <- "ILO.EMPL.EDUINTER"
int$subcat <- "2.3 Productive capabilities"

# % with advanced education
adv<-educ[educ$classif2 %in% "EDU_AGGREGATE_ADV",]
adv<-adv[,-c(2:6,9:12)]
names(adv)[c(1:3)] <-c("iso3c","year","VALUE")
adv$indicatorname <- "Share of labour force with advanced education (25+ yo)"
adv$indicatorcode <- "ILO.EMPL.EDUADV"
adv$subcat <- "2.3 Productive capabilities"
```

Finally, as usual, a dataframe is created for all ILO indicators, a source is added then it is tacked on to the Benchmark dataframe. 

```{r,  eval=FALSE} 
ilo <- rbind(partic,unemp, youth, agri, indus, serv, bas, int, adv)
ilo$cat <- "2. Prosperity"

ilo <- rbind (ilo,female)
ilo$source <- "ILO"

benchmark <-rbind(ilo,benchmark)
```
---

### WHO dataset

WHO has it's own R package as well whose directory can be found [here](https://cran.r-project.org/web/packages/rgho/rgho.pdf). While this package is not endorsed by WHO it is maintained and updated regularly so it is unlikely there are issues in the package's API access. However, periodic checks to ensure data quality may be advised. 

The WHO library is easier than ILO as there are fewer layers. All one has to do is search the available WHO datasets and find the relevant indicators within. It is easiest to search for the indicator's codes by calling the ```get_gho_codes``` command and then toggling **Help** in the bottom right window in R studio. **Codes for the GHO Dimension** should pop up and an easy CTRL+F using keywords should help you find the correct indicator. 

```{r ,  eval=FALSE} 
library(rgho)

# Search database for indicators
get_gho_codes() 
```

In the WHO database we are looking for the following indicators: <p>
- Health expenditure, total (% of GDP)
- Out-of-pocket health expenditure (% of total expenditure on health
- Population using at least basic sanitation services (%)
- Mortality rate, infant (per 1,000 live births)
- Prevalence of HIV, total (% of population ages 15-49)
- Prevalence of stunting, weight for age (% of children under 5)
- Prevalence of underweight, weight for age (% of children under 5)
- Prevalence of overweight, weight for height (% of children under 5)
- Physicians (per 1000 people)
- Hospital beds (per 10 000 people)
- Health expenditure per capita, PPP (constant 2011 international $)

For the example: After finding the ID code for health expenditure we use the command ```get_gho_data``` with dimension set to "GHO" and the code set to **GHED_CHEGDP_SHA2011**, calling the desired indicator. Columns are then removed, renamed and indicator codes/names are assigned. 

```{r ,  eval=FALSE} 
# Health expenditure %GDP
health <- get_gho_data(dimension = "GHO", code = "GHED_CHEGDP_SHA2011")
health<-health[,-c(1:2,4:5,8:11)]
names(health)[1:3] <-c("year","iso3c","VALUE")
health$indicatorname <- "Health expenditure, total (% of GDP)"
health$indicatorcode <- "HEALTH.EXP.GPD"
```

The rest follow the same format, although id code and number of excess columns should be changed to suit each indicator. Also note that filtering is not an available option with this package so some subsetting may need to be done. Always ensure the correct indicator is parsed using the ```View``` command.

```{r ,  eval=FALSE} 
# Out of pocket expenditure
oop <- get_gho_data(dimension = "GHO", code = "GHED_OOPSCHE_SHA2011")
oop<-oop[,-c(1:2,4:5,8:11)]
names(oop)[1:3] <-c("year","iso3c","VALUE")
oop$indicatorname <- "Out-of-pocket health expenditure (% of total expenditure on health"
oop$indicatorcode <- "HEALTH.OOPS.EXP"

# Access to sanitation 
sani <- get_gho_data(dimension = "GHO", code = "WSH_SANITATION_BASIC")
sani<- sani[sani$RESIDENCEAREATYPE %in% "TOTL",]
sani<-sani[,-c(1:2,4,6:7,9:11)]
names(sani)[1:3] <-c("year","iso3c","VALUE")
sani$indicatorname <- "Population using at least basic sanitation services (%)"
sani$indicatorcode <- "HEALTH.SANITATION.POP"

# Infant mortality rate (probability of death between birth and 1)
infan <- get_gho_data(dimension = "GHO", code = "MDG_0000000001", filters=list(SEX="TOTL"))
infan<-infan[,-c(1:2,4:6,8,10:13)]
names(infan)[1:3] <-c("year","iso3c","VALUE")
infan$indicatorname <- "Mortality rate, infant (per 1,000 live births)"
infan$indicatorcode <- "HEALTH.MORTALITY.PROB"

# Prevalence of HIV 
hiv <- get_gho_data(dimension = "GHO", code = "MDG_0000000029")
hiv<-hiv[,-c(1:2,4,6,8:10)]
names(hiv)[1:3] <-c("year","iso3c","VALUE")
hiv$indicatorname <- "Prevalence of HIV, total (% of population ages 15-49)"
hiv$indicatorcode <- "HEALTH.HIV.PROB"

# Stunting 
stunt <- get_gho_data(dimension = "GHO", code = "stunt5")
stunt<-stunt[,-c(1:3,5,7:14,16:18)]
names(stunt)[1:3] <-c("year","iso3c","VALUE")
stunt <- aggregate(VALUE ~ year + iso3c, stunt, FUN = mean)
stunt$indicatorname <- "Prevalence of stunting, weight for age (% of children under 5)"
stunt$indicatorcode <- "HEALTH.STUNTING"

# Underweight
under <- get_gho_data(dimension = "GHO", code = "uweight5")
under<-under[,-c(1:3,5,7:12,14:16)]
names(under)[1:3] <-c("year","iso3c","VALUE")
under <- aggregate(VALUE ~ year + iso3c, under, FUN = mean)
under$indicatorname <- "Prevalence of underweight, weight for age (% of children under 5)"
under$indicatorcode <- "HEALTH.UNDERWEIGHT"

# Overweight
over <- get_gho_data(dimension = "GHO", code = "overwgt5")
over<-over[,-c(1:3,5,7:14,16:18)]
names(over)[1:3] <-c("year","iso3c","VALUE")
over <- aggregate(VALUE ~ year + iso3c, over, FUN = mean)
over$indicatorname <- "Prevalence of overweight, weight for height (% of children under 5)"
over$indicatorcode <- "HEALTH.OVERWEIGHT"

# Physicians per 1,000 (replacing 10,000)
phys <- get_gho_data(dimension = "GHO", code = "HRH_26")
phys<-phys[,-c(1:2,4,7:10)]
names(phys)[1:3] <-c("year","iso3c","VALUE")
phys$indicatorname <-"Physicians (per 1000 people)"
phys$indicatorcode <- "HEALTH.DOC.POP"

# Hospital beds per 10,000 (DIDNT WORK)
hosp <- get_gho_data(dimension = "GHO", code = "WHS6_102")
hosp<-hosp[,-c(1:2,4,7:10)]
names(hosp)[1:3] <-c("year","iso3c","VALUE")
hosp$indicatorname <-"Hospital beds (per 10 000 people)"
hosp$indicatorcode <- "HEALTH.BEDS.POP"

# Health exp per capita
exppc <- get_gho_data(dimension = "GHO", code = "GHED_CHEGDP_SHA2011")
exppc<-exppc[,-c(1:2,4:5,8:11)]
names(exppc)[1:3] <-c("year","iso3c","VALUE")
exppc$indicatorname <-"Health expenditure per capita, PPP (constant 2011 international $)"
exppc$indicatorcode <- "HEALTH.EXP.PCAP"
```

Lastly, bind the data, add source, cat, subcat and combine with the Benchmark dataframe and you're done.

```{r ,  eval=FALSE} 
who <- rbind(exppc,hosp,phys,hiv,infan,sani,oop,health,stunt,under,over)

who$source <- "WHO"
who$cat <- "1. People"
who$subcat <- "1.5 Health"

benchmark <- rbind(benchmark,who)
```

### OECD Dataset

The final database is the OECD's. There is also a pre-built API library for the OECD but the only OECD data available for remote downloading are those that can be accessed through OECD stat. The rest must be downloaded to Excel sheets then uploaded unfortunately. The user directory can be found [here](https://cran.r-project.org/web/packages/OECD/OECD.pdf) and the more in-depth github [here](https://github.com/expersso/OECD). This package is not affiliated with the OECD but is detailed and well-maintained so using it to access the SDMX files remotely should not be a problem. 

This database is the most complicated in this guide as there are many layers and filtering is often necessary otherwise the dataset is too large to download. However, the filtering must be done in order or else they are ignored and since countries comes first in all datasets, a list of the available countries must be made to be used as a placeholder when filtering. (Inputs such as all do not work).

To browse the available datasets, use the ```get_datasets``` command which then can be seen using ```View``` or clicking on dataframe in the Global Environment. CTRL+F using keywords to find relevant datasets. 

```{r ,  eval=FALSE} 
library(OECD)

oecddsets <- get_datasets()
View(oecddsets)
```

The following indicators are found using this method: <p>
- Environmentally related taxes, % total tax revenue
- Restricted civil liberties
- Social Institutions and Gender Index 2019
- Discrimination in the family
- Restricted physical integrity
- Restricted access to productive and financial resources

For environmental taxes, the code, in this case **ERTR**, is found and so as to keep filtering in order the data structure command is called and a list of the country names in the dataset parsed using it. This is also a good time to look at the structure and find useful filters among the variables. Since we want % total tax revenue we find the code under VAR as **BASE_REV** and include it in the filter (in order of columns), then **TOT** under CAT for all tax revenues (not just energy, transport, etc.) and **TOT** under DOM for entire environment. Next the dataset can be called with ```get_dataset```, the code **ERTR** is input, the filters are added and a start time and end time. The data is then cleaned as usual and the indicator is ready.

```{r ,  eval=FALSE} 
# Environmental taxes
dstrucen <- get_data_structure("ERTR")
couenv<-dstrucen$COU
clistenv<-couenv$id

envitax<- get_dataset("ERTR",filter=list(clistenv,"BASE_REV","TOT","TOT"),
                      start_time = 2000, end_time = 2020)
envitax <- envitax[,-c(2:5,8)]
names(envitax)[1:3] <-c("iso3c","year","VALUE")
envitax$indicatorname <-"Environmentally related taxes, % total tax revenue"
envitax$indicatorcode <- "OECD.ENVTAX.REV"
```
 
For the Gender Equality indicators we use the whole dataset so it is easier as not filtering is necessary nor do we have to look at the data structure. This can be done for smaller datasets as well, following similar methodologies as WHO. Additionally, the indicator code already matches so we leave it as is, but divide the dataset to assign names and recombine at the end. 

```{r ,  eval=FALSE} 
# Gender equality indicators
gen <-get_dataset("SIGI2019")
gen <- gen[,-c(1,3,5)]
names(gen)[1:4] <-c("iso3c","indicatorcode","year","VALUE")

gen1 <- gen[gen$indicatorcode %in% "RCL__2",]
gen2 <- gen[gen$indicatorcode %in% "SIGI_2",]
gen3 <- gen[gen$indicatorcode %in% "DF__2",]
gen4 <- gen[gen$indicatorcode %in% "RPI__2",]
gen5 <- gen[gen$indicatorcode %in% "RAPFR__2",]

gen1$indicatorname<-"Restricted civil liberties"
gen2$indicatorname<-"Social Institutions and Gender Index 2019"
gen3$indicatorname<-"Discrimination in the family"
gen4$indicatorname<-"Restricted physical integrity"
gen5$indicatorname<-"Restricted access to productive and financial resources"

gen<-rbind(gen1,gen2,gen3,gen4,gen5)
```

Source is added and the Benchmark dataframe is complete!

```{r ,  eval=FALSE} 
oecd <-rbind(gen,envitax)

oecd$source <- "OECD"

benchmark <- rbind(oecd,benchmark)
```
---

### Housekeeping

Some final data cleaning is done to avoid exporting a unnecessarily large excel file.


The dataset is checked for repeated values, values before 2000 and the modeled estimates after 2020 are removed. Finally, all NAs are dropped as well.

```{r ,  eval=FALSE} 
benchmark<-benchmark %>% distinct()

benchmark <- benchmark[which(benchmark$year >= 2000),]
benchmark <- benchmark[which(benchmark$year <= 2020),]

benchmark<-na.omit(benchmark)

# Review countries listed/check for missing ones
```

Finally, from the iso3c column region indicators are dropped as well as OECD countries and other non-existant country codes. Kosovo and Chad are reassigned. 

```{r ,  eval=FALSE} 
unique(benchmark$iso3c)

benchmark$iso3c[benchmark$iso3c %in% c("KOS","XKO")] <- "XKX"
benchmark$iso3c[benchmark$iso3c %in% "CHA"] <- "TCD"

drops <- c("X01", "X02", "X03", "X04", "X05", "X06", "X07", "X08", "X09", "X10", "X11", "X12", "X13", "X14", 
            "X15", "X16", "X17", "X18", "X19", "X20", "X21", "X22", "X23", "X24", "X25", "X26", "X27", "X28", 
            "X29", "X30", "X31", "X32", "X33", "X34", "X35", "X36", "X37", "X38", "X39", "X40", "X41", "X42", 
            "X43", "X44", "X45", "X46", "X47", "X48", "X49", "X51", "X52", "X53", "X54", "X55", "X56", "X57", 
            "X58", "X59", "X60", "X61", "X62", "X63", "X64", "X65", "X66", "X67", "X68", "X69", "X70", "X71", 
            "X72", "X73", "X74", "X75", "X76", "X77", "X78", "X79", "X82", "X83", "X84", "X85", "X86", "X87", 
            "X88", "X89", "X90", "X91", "OECD", "OECDE", "OECDAO", "OECDAM", "OAVG_A", "ANT", "XDN")

clist<-countrycode(benchmark$iso3c, origin = 'iso3c', destination = 'country.name')
unique(clist) # Values missing ANT, CHA, KOS, XDN, XKO (remove ANT, XDN)

benchmark <- filter(benchmark, !(iso3c %in% drops))
```

We can then export the Benchmark dataframe as a csv file. 

```{r ,  eval=FALSE} 
write.csv(benchmark, "~/Desktop/OECD/benchmark_data_r.csv")

```

And with that it's done and ready to be uploaded onto Stata!

---

### Final comments
I think there are several things that may be possible to make this process more integrated and smooth moving forward:  <p>
1. Integrating R script into Stata (it is possible). Alternatively,
2. Move entire database onto R (Stata better with WDI though)
3. Better way to access OECD data - I think this would require a Python script to access website, download onto temporary files and aggregate a dataframe. This would take a long time but totally possible with access to OECD library. 

---

#### Tips 
1. If ever there is an error in one of the datasets it easy to reset the benchmark dataframe using the below command and re-add each dataset to find where the issue stems from.

2. If indicators are added make sure they are correctly categorized and sub-categorized with the existing code. It may be advised eventually to change the code to assign cat and subcat individually (like indicator name and code).

```{r ,  eval=FALSE} 
benchmark <- ""
```
